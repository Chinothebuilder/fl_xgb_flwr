{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9me8fEtRqHBO"
      },
      "source": [
        "## Starter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CHaJ0DjrKc5Q",
        "outputId": "afc52c5c-1f44-4ec4-dced-6b08814d5d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting hummingbird-ml\n",
            "  Downloading hummingbird_ml-0.4.11-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.0/151.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flwr[simulation]\n",
            "  Downloading flwr-1.9.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.7/364.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ezkl\n",
            "  Downloading ezkl-11.4.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml) (1.2.2)\n",
            "Requirement already satisfied: torch>1.7.0 in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml) (2.3.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml) (5.9.5)\n",
            "Collecting dill (from hummingbird-ml)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml) (3.20.3)\n",
            "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (42.0.8)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.64.1)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr[simulation])\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Collecting pathspec<0.13.0,>=0.12.1 (from flwr[simulation])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting protobuf>=3.20.2 (from hummingbird-ml)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome<4.0.0,>=3.18.0 (from flwr[simulation])\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (2.0.1)\n",
            "Collecting typer[all]<0.10.0,>=0.9.0 (from flwr[simulation])\n",
            "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray==2.10.0 (from flwr[simulation])\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (3.15.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (2.31.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests (from ray==2.10.0->flwr[simulation])\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr[simulation]) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "INFO: pip is looking at multiple versions of onnxconverter-common to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml)\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (2024.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>1.7.0->hummingbird-ml) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>1.7.0->hummingbird-ml) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>1.7.0->hummingbird-ml) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>1.7.0->hummingbird-ml)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.7.0->hummingbird-ml) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>1.7.0->hummingbird-ml)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama<0.5.0,>=0.4.3 (from typer[all]<0.10.0,>=0.9.0->flwr[simulation])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (13.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->hummingbird-ml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->hummingbird-ml) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>1.7.0->hummingbird-ml) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.18.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>1.7.0->hummingbird-ml) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.1.2)\n",
            "Installing collected packages: tenseal, xxhash, typer, requests, pycryptodome, pyarrow, protobuf, pathspec, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iterators, ezkl, dill, colorama, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, onnxconverter-common, nvidia-cusolver-cu12, ray, flwr, datasets, hummingbird-ml\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 datasets-2.20.0 dill-0.3.8 ezkl-11.4.2 flwr-1.9.0 hummingbird-ml-0.4.11 iterators-0.0.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnx-1.16.1 onnxconverter-common-1.13.0 pathspec-0.12.1 protobuf-4.25.3 pyarrow-16.1.0 pycryptodome-3.20.0 ray-2.10.0 requests-2.32.3 tenseal-0.3.14 typer-0.9.4 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal matplotlib hummingbird-ml onnx flwr[simulation] ezkl torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DbIKEiDo0du"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import trange, tqdm\n",
        "import flwr as fl\n",
        "from flwr.common.typing import Parameters\n",
        "from collections import OrderedDict\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "from flwr.common import NDArray, NDArrays\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchmetrics import Accuracy, MeanSquaredError\n",
        "from tqdm import trange, tqdm\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jvwFp29ElhkG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from xgboost import XGBClassifier as Gbc\n",
        "import numpy as np\n",
        "from flwr.common.logger import log\n",
        "from typing import Dict, List, Optional\n",
        "from flwr.server.strategy import FedXgbBagging, FedXgbCyclic\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import argparse\n",
        "import os\n",
        "from typing import List\n",
        "import flwr as fl\n",
        "import json\n",
        "import torch\n",
        "import ezkl\n",
        "import tenseal as ts\n",
        "from torch import nn\n",
        "import xgboost as xgb\n",
        "from hummingbird.ml import convert\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from flwr.common import (Code, EvaluateIns, EvaluateRes, FitIns, FitRes, GetParametersIns, GetParametersRes, Parameters, Status,)\n",
        "from sklearn.exceptions import NotFittedError\n",
        "import pandas as pd\n",
        "from flwr.common.logger import log\n",
        "from logging import INFO, ERROR\n",
        "%matplotlib inline\n",
        "import time\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "sns.set(style='white', context='notebook', palette='deep')\n",
        "import tenseal as ts\n",
        "from typing import List\n",
        "import asyncio\n",
        "import threading\n",
        "import time\n",
        "import base64\n",
        "import warnings\n",
        "#import nest_asyncio\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "#nest_asyncio.apply()\n",
        "kfold = StratifiedKFold(n_splits=5)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4LhbMqPUqSn"
      },
      "outputs": [],
      "source": [
        "class preamble:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def data_preprocessing(self):\n",
        "        data = pd.read_csv(self.file_path)\n",
        "        data['HeartDisease'] = data['HeartDisease'].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "        X = data.drop(columns=['HeartDisease'])\n",
        "        y = data['HeartDisease']\n",
        "\n",
        "        categorical_columns = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "        numerical_columns = X.select_dtypes(include=['int', 'float']).columns.tolist()\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        label_encoder = LabelEncoder()\n",
        "        X[categorical_columns] = X[categorical_columns].apply(lambda col: label_encoder.fit_transform(col))\n",
        "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
        "\n",
        "        # Separate features and labels\n",
        "        X = X.to_numpy()\n",
        "        y = y.to_numpy()\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=71)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2En4AbiGQp7"
      },
      "outputs": [],
      "source": [
        "target_column = 'HeartDisease'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp48htyGqXpM"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your Excel file\n",
        "file_path = 'heart_2020_cleaned.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvTG3JPPVLLE"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier as GBC\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eta\": 0.1,  # Learning rate\n",
        "    \"max_depth\": 8,\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"nthread\": 16,\n",
        "    \"num_parallel_tree\": 1,\n",
        "    \"subsample\": 1,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"booster\" : 'gbtree',\n",
        "}\n",
        "model = GBC(**params)\n",
        "#model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFCgDrR4WWk2"
      },
      "outputs": [],
      "source": [
        "p = preamble(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CosUgUGnedgE"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = p.data_preprocessing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EDS0rrBrNFF",
        "outputId": "f6b52947-b4fb-41ac-cbf2-3687bfa7dad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(79102, 17)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ypzEWkzrQi0",
        "outputId": "7f7c7556-8d14-46d6-f8fb-adbd5f36a961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13960, 17)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm7Jc6yNoQEO",
        "outputId": "461b5786-2372-43a3-c432-102537947c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature dimension of the dataset: 17\n",
            "Size of the trainset: 79102\n",
            "Size of the testset: 13960\n"
          ]
        }
      ],
      "source": [
        "print(\"Feature dimension of the dataset:\", X_train.shape[1])\n",
        "print(\"Size of the trainset:\", X_train.shape[0])\n",
        "print(\"Size of the testset:\", X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5QX28KdoP_-",
        "outputId": "cde7a434-403f-45b8-f7ba-3a39d294ac33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "class_num_train = len(set(y_train))\n",
        "class_num_test = len(set(y_test))\n",
        "print(class_num_train)\n",
        "print(class_num_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk_ToJR6o37G"
      },
      "outputs": [],
      "source": [
        "#pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FotplhS3Of25"
      },
      "source": [
        "### Construct the trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cytJ2wupHbN"
      },
      "outputs": [],
      "source": [
        "def construct_tree(\n",
        "    # Inital 'dataset' was Dataset of pytorch\n",
        "    dataset: Dataset, label: NDArray, n_estimators, tree_type: str, learning_rate=0.05, max_depth=30, booster='gbtree',random_state=0, subsample=0.9,\n",
        "    colsample_bytree=0.9, alpha=5, gamma=5, min_child_weight=1, eval_metric='mlogloss', reg_lambda=1500, verbose=2020, max_leaves=30\n",
        ") -> Union[XGBClassifier, XGBRegressor]:\n",
        "    \"\"\"Construct a xgboost tree from tabular dataset for multiclass classification.\"\"\"\n",
        "    if tree_type == \"MULTICLASS\":\n",
        "        tree = XGBClassifier(\n",
        "            objective=\"multi:softprob\",\n",
        "            num_class=len(np.unique(y_test)),  # Number of unique classes in the label\n",
        "            learning_rate=learning_rate,\n",
        "            max_depth=max_depth,\n",
        "            n_estimators=n_estimators,\n",
        "            subsample=subsample,\n",
        "            colsample_bylevel=1,\n",
        "            colsample_bynode=1,\n",
        "            colsample_bytree=colsample_bytree,\n",
        "            alpha=alpha,\n",
        "            gamma=gamma,\n",
        "            num_parallel_tree=1,\n",
        "            min_child_weight=min_child_weight,\n",
        "            random_state=random_state,\n",
        "            booster=booster,\n",
        "            eval_metric=eval_metric,\n",
        "            reg_lambda=reg_lambda,\n",
        "            verbose=verbose,\n",
        "            max_leaves=max_leaves\n",
        "        )\n",
        "\n",
        "    elif tree_type == \"REG\":\n",
        "        tree = xgb.XGBRegressor(\n",
        "            objective=\"reg:squarederror\",\n",
        "            learning_rate=0.1,\n",
        "            max_depth=8,\n",
        "            n_estimators=n_estimators,\n",
        "            subsample=0.8,\n",
        "            colsample_bylevel=1,\n",
        "            colsample_bynode=1,\n",
        "            colsample_bytree=1,\n",
        "            alpha=5,\n",
        "            gamma=5,\n",
        "            num_parallel_tree=1,\n",
        "            min_child_weight=1,\n",
        "        )\n",
        "\n",
        "    tree.fit(dataset, label)\n",
        "    return tree\n",
        "\n",
        "def construct_tree_from_loader(\n",
        "    dataset_loader: DataLoader, n_estimators: int, tree_type: str\n",
        ") -> Union[XGBClassifier, XGBRegressor]:\n",
        "    \"\"\"Construct a xgboost tree form tabular dataset loader.\"\"\"\n",
        "    for dataset in dataset_loader:\n",
        "        data, label = dataset[0], dataset[1]\n",
        "    print(f\"Data: {data}\")\n",
        "    print(f\"label: {label}\")\n",
        "    return construct_tree(data, label, n_estimators, tree_type)\n",
        "\n",
        "def single_tree_prediction(\n",
        "    tree: Union[XGBClassifier, XGBRegressor], n_tree: int, dataset: NDArray\n",
        ") -> Optional[NDArray]:\n",
        "    \"\"\"Extract the prediction result of a single tree in the xgboost tree\n",
        "    ensemble.\"\"\"\n",
        "    # How to access a single tree\n",
        "    # https://github.com/bmreiniger/datascience.stackexchange/blob/master/57905.ipynb\n",
        "    num_t = len(tree.get_booster().get_dump())\n",
        "    if n_tree > num_t:\n",
        "        print(\n",
        "            \"The tree index to be extracted is larger than the total number of trees.\"\n",
        "        )\n",
        "        return None\n",
        "    prediction = tree.predict(  # type: ignore\n",
        "        dataset, iteration_range=(n_tree, n_tree + 1), output_margin=True\n",
        "    )\n",
        "    if len(prediction) > 1:\n",
        "        prediction = np.argmax(prediction, axis=1)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n",
        "def tree_encoding(  # pylint: disable=R0914\n",
        "    trainloader: DataLoader,\n",
        "    client_trees: Union[\n",
        "        Tuple[XGBClassifier, int],\n",
        "        Tuple[XGBRegressor, int],\n",
        "        List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "    ],\n",
        "    client_tree_num: int,\n",
        "    client_num: int,\n",
        ") -> Optional[Tuple[NDArray, NDArray]]:\n",
        "    \"\"\"Transform the tabular dataset into prediction results using the\n",
        "    aggregated xgboost tree ensembles from all clients.\"\"\"\n",
        "    if trainloader is None:\n",
        "        print(\"Trainloader is None\")\n",
        "        return None\n",
        "\n",
        "    for local_dataset in trainloader:\n",
        "        x_train, y_train = local_dataset[0], local_dataset[1]\n",
        "\n",
        "    print(f\"Train data: {x_train}\")\n",
        "    print(f\"Train labels: {y_train}\")\n",
        "    x_train_enc = np.zeros((x_train.shape[0], client_num * client_tree_num))\n",
        "    x_train_enc = np.array(x_train_enc, copy=True)\n",
        "\n",
        "    temp_trees: Any = None\n",
        "    if isinstance(client_trees, list) is False:\n",
        "        print(\"isintance if condition - 1\")\n",
        "        temp_trees = [client_trees[0]] * client_num\n",
        "    elif isinstance(client_trees, list) and len(client_trees) != client_num:\n",
        "        print(\"isintance if condition - 2\")\n",
        "        temp_trees = [client_trees[0][0]] * client_num\n",
        "    else:\n",
        "        print(\"Else condition\")\n",
        "        cids = []\n",
        "        temp_trees = []\n",
        "        for i, _ in enumerate(client_trees):\n",
        "            temp_trees.append(client_trees[i][0])  # type: ignore\n",
        "            cids.append(client_trees[i][1])  # type: ignore\n",
        "        sorted_index = np.argsort(np.asarray(cids))\n",
        "        temp_trees = np.asarray(temp_trees)[sorted_index]\n",
        "        print(cids)\n",
        "\n",
        "    for i, _ in enumerate(temp_trees):\n",
        "        for j in range(client_tree_num):\n",
        "            x_train_enc[:, i * client_tree_num + j] = single_tree_prediction(\n",
        "                temp_trees[i], j, x_train\n",
        "            )\n",
        "\n",
        "    x_train_enc32: Any = np.float32(x_train_enc)\n",
        "    y_train32: Any = np.float32(y_train)\n",
        "\n",
        "    x_train_enc32, y_train32 = torch.from_numpy(\n",
        "        np.expand_dims(x_train_enc32, axis=1)  # type: ignore\n",
        "    ), torch.from_numpy(\n",
        "        np.expand_dims(y_train32, axis=-1)  # type: ignore\n",
        "    )\n",
        "    return x_train_enc32, y_train32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpBHffAjpRDW"
      },
      "outputs": [],
      "source": [
        "task_type = \"MULTICLASS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu-YPT56pUct"
      },
      "outputs": [],
      "source": [
        "class TreeDataset(Dataset):\n",
        "    def __init__(self, data: NDArray, labels: NDArray) -> None:\n",
        "        self.labels = labels\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[int, NDArray]:\n",
        "        label = self.labels[idx]\n",
        "        data = self.data[idx, :]\n",
        "        sample = {0: data, 1: label}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrTuVETpUaF"
      },
      "outputs": [],
      "source": [
        "trainset = TreeDataset(np.array(X_train, copy=True), np.array(y_train, copy=True))\n",
        "testset = TreeDataset(np.array(X_test, copy=True), np.array(y_test, copy=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex7-XMi_pUW-"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(\n",
        "    dataset: Dataset, partition: str, batch_size: Union[int, str]\n",
        ") -> DataLoader:\n",
        "    if batch_size == \"whole\":\n",
        "        batch_size = len(dataset)\n",
        "    return DataLoader(\n",
        "        dataset, batch_size=batch_size, pin_memory=True, shuffle=(partition == \"train\")\n",
        "    )\n",
        "\n",
        "# https://github.com/adap/flower\n",
        "def do_fl_partitioning(\n",
        "    trainset: Dataset,\n",
        "    testset: Dataset,\n",
        "    pool_size: int,\n",
        "    batch_size: Union[int, str],\n",
        "    val_ratio: float = 0.0,\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // pool_size\n",
        "    lengths = [partition_size] * pool_size\n",
        "    if sum(lengths) != len(trainset):\n",
        "        lengths[-1] = len(trainset) - sum(lengths[0:-1])\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(0))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = int(len(ds) * val_ratio)\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(0))\n",
        "        trainloaders.append(get_dataloader(ds_train, \"train\", batch_size))\n",
        "        if len_val != 0:\n",
        "            valloaders.append(get_dataloader(ds_val, \"val\", batch_size))\n",
        "        else:\n",
        "            valloaders = None\n",
        "    testloader = get_dataloader(testset, \"test\", batch_size)\n",
        "    if trainloaders:\n",
        "        for local_dataset in trainloaders[0]:\n",
        "             print(f\"Trainloaders data shape: {local_dataset[0].shape}, Label shape: {local_dataset[1].shape}\")\n",
        "    if testloader:\n",
        "        for local_dataset in testloader:\n",
        "             print(f\"Testloaders data shape: {local_dataset[0].shape}, Label shape: {local_dataset[1].shape}\")\n",
        "    return trainloaders, valloaders, testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkz0bTiAqiXu",
        "outputId": "7510c60a-6dca-4be2-d011-73765436274a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainloaders data shape: torch.Size([26367, 17]), Label shape: torch.Size([26367])\n",
            "Testloaders data shape: torch.Size([13960, 17]), Label shape: torch.Size([13960])\n"
          ]
        }
      ],
      "source": [
        "# The number of clients participated in the federated learning\n",
        "client_num = 3\n",
        "\n",
        "# The number of XGBoost trees in the tree ensemble that will be built for each client\n",
        "# client_tree_num = 300 // client_num\n",
        "client_tree_num = 600 // client_num\n",
        "\n",
        "client_trees_comparison = []\n",
        "trainloader, _, testloader = do_fl_partitioning(\n",
        "    trainset, testset, pool_size=client_num, batch_size=\"whole\", val_ratio=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ2THf9yt7jx"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "# num_classes - None\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_channel: int = 64, num_classes: int = 12, task_type: str = \"MULTICLASS\") -> None:\n",
        "        super(CNN, self).__init__()\n",
        "        n_out = num_classes\n",
        "        self.task_type = task_type\n",
        "        self.conv1d = nn.Conv1d(\n",
        "            1, n_channel, kernel_size=client_tree_num, stride=client_tree_num, padding=0\n",
        "        )\n",
        "        self.layer_direct = nn.Linear(n_channel * client_num, n_out)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.Softmax = nn.Softmax(dim=1)\n",
        "        self.Identity = nn.Identity()\n",
        "\n",
        "        # Add weight initialization\n",
        "        for layer in self.modules():\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(\n",
        "                    layer.weight, mode=\"fan_in\", nonlinearity=\"relu\"\n",
        "                )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.ReLU(self.conv1d(x))\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.ReLU(x)\n",
        "        x = self.layer_direct(x)\n",
        "        if self.task_type == \"MULTICLASS\":\n",
        "            x = self.Softmax(x)\n",
        "        elif self.task_type == \"REG\":\n",
        "            x = self.Identity(x)\n",
        "        return x\n",
        "    def get_weights(self) -> fl.common.NDArrays:\n",
        "        \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "        return [\n",
        "            np.array(val.cpu().numpy(), copy=True)\n",
        "            for _, val in self.state_dict().items()\n",
        "        ]\n",
        "\n",
        "    def set_weights(self, weights: fl.common.NDArrays) -> None:\n",
        "        \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
        "        layer_dict = {}\n",
        "        for k, v in zip(self.state_dict().keys(), weights):\n",
        "            if v.ndim != 0:\n",
        "                layer_dict[k] = torch.Tensor(np.array(v, copy=True))\n",
        "        state_dict = OrderedDict(layer_dict)\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(\n",
        "    task_type: str,\n",
        "    net: CNN,\n",
        "    trainloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    num_iterations: int,\n",
        "    log_progress: bool = True,\n",
        ") -> Tuple[float, float, int]:\n",
        "    # Define loss and optimizer\n",
        "    if task_type == \"MULTICLASS\":\n",
        "        criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multiclass classification\n",
        "    elif task_type == \"REG\":\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "    def cycle(iterable):\n",
        "        \"\"\"Repeats the contents of the train loader, in case it gets exhausted in 'num_iterations'.\"\"\"\n",
        "        while True:\n",
        "            for x in iterable:\n",
        "                yield x\n",
        "\n",
        "\n",
        "    # Train the network\n",
        "    net.train()\n",
        "    total_loss, total_result, n_samples = 0.0, 0.0, 0\n",
        "    pbar = (\n",
        "        tqdm(iter(cycle(trainloader)), total=num_iterations, desc=f\"TRAIN\")\n",
        "        if log_progress\n",
        "        else iter(cycle(trainloader))\n",
        "    )\n",
        "\n",
        "    for i, data in zip(range(num_iterations), pbar):\n",
        "        tree_outputs, labels = data[0].to(device), data[1].to(device)\n",
        "        labels = labels.squeeze()\n",
        "        labels = labels.to(torch.long)\n",
        "        outputs = net(tree_outputs)\n",
        "        log_probs = F.log_softmax(outputs, dim=1)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(log_probs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collected training loss and accuracy statistics\n",
        "        total_loss += loss.item()\n",
        "        n_samples += labels.size(0)\n",
        "\n",
        "        if task_type == \"MULTICLASS\":\n",
        "            class_predictions = torch.argmax(log_probs, dim=1)\n",
        "            acc = Accuracy(task=\"multiclass\",num_classes=12)(\n",
        "                class_predictions.cpu().int(), labels.type(torch.int).cpu()\n",
        "                )\n",
        "            total_result += acc * labels.size(0)\n",
        "\n",
        "        if log_progress:\n",
        "            if task_type == \"MULTICLASS\":\n",
        "                pbar.set_postfix(\n",
        "                    {\n",
        "                        \"train_loss\": total_loss / n_samples,\n",
        "                        \"train_acc\": total_result / n_samples,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_loss / n_samples, total_result / n_samples, n_samples\n",
        "\n",
        "def test(\n",
        "    task_type: str,\n",
        "    net: CNN,\n",
        "    testloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    log_progress: bool = True,\n",
        ") -> Tuple[float, float, int]:\n",
        "    \"\"\"Evaluates the network on test data.\"\"\"\n",
        "    # Define loss function for multiclass classification\n",
        "    if task_type == \"MULTICLASS\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    elif task_type == \"REG\":\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "    total_loss, total_result, n_samples = 0.0, 0.0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        print(f\"Testloader: {testloader}\")\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            tree_outputs, labels = data[0].to(device), data[1].to(device)\n",
        "            labels = labels.squeeze()\n",
        "            labels = labels.to(torch.long)\n",
        "            outputs = net(tree_outputs)\n",
        "            log_probs = F.log_softmax(outputs, dim=1)\n",
        "\n",
        "            # Collected testing loss and accuracy statistics\n",
        "            # Error with test\n",
        "            total_loss += criterion(log_probs, labels).item()\n",
        "            n_samples += labels.size(0)\n",
        "\n",
        "            if task_type == \"MULTICLASS\":\n",
        "                class_predictions = torch.argmax(log_probs, dim=1)\n",
        "                acc = Accuracy(task=\"multiclass\", num_classes=12)(\n",
        "                    class_predictions.cpu().int(), labels.type(torch.int).cpu()\n",
        "                )\n",
        "                total_result += acc * labels.size(0)\n",
        "\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_loss / n_samples, total_result / n_samples, n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFoyoAH4t7hC"
      },
      "outputs": [],
      "source": [
        "def tree_encoding_loader(\n",
        "    dataloader: DataLoader,\n",
        "    batch_size: int,\n",
        "    client_trees: Union[\n",
        "        Tuple[XGBClassifier, int],\n",
        "        Tuple[XGBRegressor, int],\n",
        "        List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "    ],\n",
        "    client_tree_num: int,\n",
        "    client_num: int,\n",
        ") -> DataLoader:\n",
        "    encoding = tree_encoding(dataloader, client_trees, client_tree_num, client_num)\n",
        "    if encoding is None:\n",
        "        print(\"Encoding is None\")\n",
        "        return None\n",
        "    data, labels = encoding\n",
        "    tree_dataset = TreeDataset(data, labels)\n",
        "    print(f\"client trees: {client_trees}\")\n",
        "    # Error\n",
        "    print(f\"tree dataset: {tree_dataset}\")\n",
        "    return get_dataloader(tree_dataset, \"tree\", batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvB1mHg2unV_"
      },
      "source": [
        "### Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZDcVmVhufeg"
      },
      "outputs": [],
      "source": [
        "# Flower client\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetPropertiesIns,\n",
        "    GetPropertiesRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        "    Code,\n",
        "    parameters_to_ndarrays,\n",
        "    ndarrays_to_parameters,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ETBt3cTqiUt"
      },
      "outputs": [],
      "source": [
        "class FL_Client(fl.client.Client):\n",
        "    def __init__(\n",
        "        self,\n",
        "        task_type: str,\n",
        "        trainloader: DataLoader,\n",
        "        valloader: DataLoader,\n",
        "        client_tree_num: int,\n",
        "        client_num: int,\n",
        "        num_classes: int,\n",
        "        cid: str,\n",
        "        log_progress: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Creates a client for training `network.Net` on tabular dataset.\n",
        "        \"\"\"\n",
        "        self.task_type = task_type\n",
        "        self.num_classes = num_classes  # Store the number of classes\n",
        "        self.cid = cid\n",
        "        self.tree = construct_tree_from_loader(trainloader, client_tree_num, task_type)\n",
        "        self.trainloader_original = trainloader\n",
        "        self.valloader_original = valloader\n",
        "        self.trainloader = None\n",
        "        self.valloader = None\n",
        "        self.client_tree_num = client_tree_num\n",
        "        self.client_num = client_num\n",
        "        self.properties = {\"tensor_type\": \"numpy.ndarray\"}\n",
        "        self.log_progress = log_progress\n",
        "\n",
        "        # Instantiate model with num_classes\n",
        "        self.net = CNN()\n",
        "\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_properties(self, ins: GetPropertiesIns) -> GetPropertiesRes:\n",
        "        return GetPropertiesRes(properties=self.properties)\n",
        "\n",
        "    def get_parameters(\n",
        "        self, ins: GetParametersIns, group_id: str\n",
        "    ) -> Tuple[\n",
        "        GetParametersRes, Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]\n",
        "    ]:\n",
        "        return [\n",
        "            GetParametersRes(\n",
        "                status=Status(Code.OK, \"\"),\n",
        "                parameters=ndarrays_to_parameters(self.net.get_weights()),\n",
        "            ),\n",
        "            (self.tree, int(self.cid)),\n",
        "            group_id  # Return the group_id\n",
        "        ]\n",
        "\n",
        "    def set_parameters(\n",
        "        self,\n",
        "        parameters: Tuple[\n",
        "            Parameters,\n",
        "            Union[\n",
        "                Tuple[XGBClassifier, int],\n",
        "                Tuple[XGBRegressor, int],\n",
        "                List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "            ],\n",
        "        ],\n",
        "    ) -> Union[\n",
        "        Tuple[XGBClassifier, int],\n",
        "        Tuple[XGBRegressor, int],\n",
        "        List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "    ]:\n",
        "        self.net.set_weights(parameters_to_ndarrays(parameters[0]))\n",
        "        return parameters[1]\n",
        "\n",
        "    def fit(self, fit_params: FitIns) -> FitRes:\n",
        "        # Process incoming request to train\n",
        "        num_iterations = fit_params.config[\"num_iterations\"]\n",
        "        batch_size = fit_params.config[\"batch_size\"]\n",
        "        aggregated_trees = self.set_parameters(fit_params.parameters)\n",
        "\n",
        "        if type(aggregated_trees) is list:\n",
        "            print(\"Client \" + self.cid + \": recieved\", len(aggregated_trees), \"trees\")\n",
        "        else:\n",
        "            print(\"Client \" + self.cid + \": only had its own tree\")\n",
        "        self.trainloader = tree_encoding_loader(\n",
        "            self.trainloader_original,\n",
        "            batch_size,\n",
        "            aggregated_trees,\n",
        "            self.client_tree_num,\n",
        "            self.client_num,\n",
        "        )\n",
        "        self.valloader = tree_encoding_loader(\n",
        "            self.valloader_original,\n",
        "            batch_size,\n",
        "            aggregated_trees,\n",
        "            self.client_tree_num,\n",
        "            self.client_num,\n",
        "        )\n",
        "\n",
        "        # num_iterations = None special behaviour: train(...) runs for a single epoch, however many updates it may be\n",
        "        # num_iterations = num_iterations or len(self.trainloader)\n",
        "        num_iterations = len(self.trainloader)\n",
        "\n",
        "        # Train the model\n",
        "        print(f\"Client {self.cid}: training for {num_iterations} iterations/updates\")\n",
        "        self.net.to(self.device)\n",
        "        train_loss, train_result, num_examples = train(\n",
        "            self.task_type,\n",
        "            self.net,\n",
        "            self.trainloader,\n",
        "            device=self.device,\n",
        "            num_iterations=num_iterations,\n",
        "            log_progress=self.log_progress,\n",
        "        )\n",
        "        print(\n",
        "            f\"Client {self.cid}: training round complete, {num_examples} examples processed\"\n",
        "        )\n",
        "        group_id = self.cid  # Use client ID as group ID\n",
        "        if self.task_type == \"MULTICLASS\":\n",
        "            return FitRes(\n",
        "                status=Status(Code.OK, \"\"),\n",
        "                parameters=self.get_parameters(fit_params.config, group_id=group_id),\n",
        "                num_examples=num_examples,\n",
        "                metrics={\"loss\": train_loss, \"accuracy\": train_result},\n",
        "            )\n",
        "        elif self.task_type == \"REG\":\n",
        "            return FitRes(\n",
        "                status=Status(Code.OK, \"\"),\n",
        "                parameters=self.get_parameters(fit_params.config, group_id=group_id),\n",
        "                num_examples=num_examples,\n",
        "                metrics={\"loss\": train_loss, \"mse\": train_result},\n",
        "            )\n",
        "\n",
        "    def evaluate(self, eval_params: EvaluateIns) -> EvaluateRes:\n",
        "        # Process incoming request to evaluate\n",
        "        self.set_parameters(eval_params.parameters)\n",
        "\n",
        "        # Evaluate the model\n",
        "        self.net.to(self.device)\n",
        "        loss, result, num_examples = test(\n",
        "            self.task_type,\n",
        "            self.net,\n",
        "            self.valloader,\n",
        "            device=self.device,\n",
        "            log_progress=self.log_progress,\n",
        "        )\n",
        "\n",
        "        # Return evaluation information\n",
        "        if self.task_type == \"MULTICLASS\":\n",
        "            print(\n",
        "                f\"Client {self.cid}: evaluation on {num_examples} examples: loss={loss:.4f}, accuracy={result:.4f}\"\n",
        "            )\n",
        "            return EvaluateRes(\n",
        "                status=Status(Code.OK, \"\"),\n",
        "                loss=loss,\n",
        "                num_examples=num_examples,\n",
        "                metrics={\"accuracy\": result},\n",
        "            )\n",
        "        elif self.task_type == \"REG\":\n",
        "            print(\n",
        "                f\"Client {self.cid}: evaluation on {num_examples} examples: loss={loss:.4f}, mse={result:.4f}\"\n",
        "            )\n",
        "            return EvaluateRes(\n",
        "                status=Status(Code.OK, \"\"),\n",
        "                loss=loss,\n",
        "                num_examples=num_examples,\n",
        "                metrics={\"mse\": result},\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe6ovlJCuroI"
      },
      "source": [
        "### Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w3HFd-5urR0"
      },
      "outputs": [],
      "source": [
        "# Flower server\n",
        "import functools\n",
        "from flwr.server.strategy import FedXgbNnAvg\n",
        "from flwr.server.app import ServerConfig\n",
        "\n",
        "import timeit\n",
        "from logging import DEBUG, INFO\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import DisconnectRes, Parameters, ReconnectIns, Scalar\n",
        "from flwr.common.logger import log\n",
        "from flwr.common.typing import GetParametersIns\n",
        "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.history import History\n",
        "from flwr.server.strategy import Strategy\n",
        "from flwr.server.server import (\n",
        "    reconnect_clients,\n",
        "    reconnect_client,\n",
        "    fit_clients,\n",
        "    fit_client,\n",
        "    _handle_finished_future_after_fit,\n",
        "    evaluate_clients,\n",
        "    evaluate_client,\n",
        "    _handle_finished_future_after_evaluate,\n",
        ")\n",
        "\n",
        "FitResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, FitRes]],\n",
        "    List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "]\n",
        "EvaluateResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, EvaluateRes]],\n",
        "    List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "Ojc5-CbHurM3"
      },
      "outputs": [],
      "source": [
        "class FL_Server(fl.server.Server):\n",
        "    \"\"\"Flower server.\"\"\"\n",
        "    def __init__(\n",
        "        self, *, client_manager: ClientManager, strategy: Optional[Strategy] = None\n",
        "    ) -> None:\n",
        "        self._client_manager: ClientManager = client_manager\n",
        "        self.parameters: Parameters = Parameters(\n",
        "            tensors=[], tensor_type=\"numpy.ndarray\"\n",
        "        )\n",
        "        self.strategy: Strategy = strategy\n",
        "        self.max_workers: Optional[int] = None\n",
        "\n",
        "    # pylint: disable=too-many-locals\n",
        "    def fit(self, num_rounds: int, timeout: Optional[float]) -> History:\n",
        "        \"\"\"Run federated averaging for a number of rounds.\"\"\"\n",
        "        history = History()\n",
        "\n",
        "        # Initialize parameters\n",
        "        log(INFO, \"Initializing global parameters\")\n",
        "        self.parameters = self._get_initial_parameters(timeout=timeout)\n",
        "\n",
        "        log(INFO, \"Evaluating initial parameters\")\n",
        "        res = self.strategy.evaluate(0, parameters=self.parameters)\n",
        "        if res is not None:\n",
        "            log(\n",
        "                INFO,\n",
        "                \"initial parameters (loss, other metrics): %s, %s\",\n",
        "                res[0],\n",
        "                res[1],\n",
        "            )\n",
        "            history.add_loss_centralized(server_round=0, loss=res[0])\n",
        "            history.add_metrics_centralized(server_round=0, metrics=res[1])\n",
        "\n",
        "        # Run federated learning for num_rounds\n",
        "        log(INFO, \"FL starting\")\n",
        "        start_time = timeit.default_timer()\n",
        "\n",
        "        for current_round in range(1, num_rounds + 1):\n",
        "            # Train model and replace previous global model\n",
        "            res_fit = self.fit_round(server_round=current_round, timeout=timeout)\n",
        "            if res_fit:\n",
        "                parameters_prime, _, _ = res_fit  # fit_metrics_aggregated\n",
        "                if parameters_prime:\n",
        "                    self.parameters = parameters_prime\n",
        "\n",
        "            # Evaluate model using strategy implementation\n",
        "            res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
        "            if res_cen is not None:\n",
        "                loss_cen, metrics_cen = res_cen\n",
        "                log(\n",
        "                    INFO,\n",
        "                    \"fit progress: (%s, %s, %s, %s)\",\n",
        "                    current_round,\n",
        "                    loss_cen,\n",
        "                    metrics_cen,\n",
        "                    timeit.default_timer() - start_time,\n",
        "                )\n",
        "                history.add_loss_centralized(server_round=current_round, loss=loss_cen)\n",
        "                history.add_metrics_centralized(\n",
        "                    server_round=current_round, metrics=metrics_cen\n",
        "                )\n",
        "\n",
        "            # Evaluate model on a sample of available clients\n",
        "            res_fed = self.evaluate_round(server_round=current_round, timeout=timeout)\n",
        "            if res_fed:\n",
        "                loss_fed, evaluate_metrics_fed, _ = res_fed\n",
        "                if loss_fed:\n",
        "                    history.add_loss_distributed(\n",
        "                        server_round=current_round, loss=loss_fed\n",
        "                    )\n",
        "                    history.add_metrics_distributed(\n",
        "                        server_round=current_round, metrics=evaluate_metrics_fed\n",
        "                    )\n",
        "\n",
        "        # Bookkeeping\n",
        "        end_time = timeit.default_timer()\n",
        "        elapsed = end_time - start_time\n",
        "        log(INFO, \"FL finished in %s\", elapsed)\n",
        "        return history\n",
        "\n",
        "    def evaluate_round(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        timeout: Optional[float],\n",
        "    ) -> Optional[\n",
        "        Tuple[Optional[float], Dict[str, Scalar], EvaluateResultsAndFailures]\n",
        "    ]:\n",
        "        \"\"\"Validate current global model on a number of clients.\"\"\"\n",
        "\n",
        "        # Get clients and their respective instructions from strategy\n",
        "        client_instructions = self.strategy.configure_evaluate(\n",
        "            server_round=server_round,\n",
        "            parameters=self.parameters,\n",
        "            client_manager=self._client_manager,\n",
        "        )\n",
        "        if not client_instructions:\n",
        "            log(INFO, \"evaluate_round %s: no clients selected, cancel\", server_round)\n",
        "            return None\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"evaluate_round %s: strategy sampled %s clients (out of %s)\",\n",
        "            server_round,\n",
        "            len(client_instructions),\n",
        "            self._client_manager.num_available(),\n",
        "        )\n",
        "\n",
        "        # Collect `evaluate` results from all clients participating in this round\n",
        "        results, failures = evaluate_clients(\n",
        "            client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "        )\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"evaluate_round %s received %s results and %s failures\",\n",
        "            server_round,\n",
        "            len(results),\n",
        "            len(failures),\n",
        "        )\n",
        "\n",
        "        # Aggregate the evaluation results\n",
        "        aggregated_result: Tuple[\n",
        "            Optional[float],\n",
        "            Dict[str, Scalar],\n",
        "        ] = self.strategy.aggregate_evaluate(server_round, results, failures)\n",
        "\n",
        "        loss_aggregated, metrics_aggregated = aggregated_result\n",
        "        return loss_aggregated, metrics_aggregated, (results, failures)\n",
        "\n",
        "    def fit_round(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        timeout: Optional[float],\n",
        "    ) -> Optional[\n",
        "        Tuple[\n",
        "            Optional[\n",
        "                Tuple[\n",
        "                    Parameters,\n",
        "                    Union[\n",
        "                        Tuple[XGBClassifier, int],\n",
        "                        Tuple[XGBRegressor, int],\n",
        "                        List[\n",
        "                            Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]\n",
        "                        ],\n",
        "                    ],\n",
        "                ]\n",
        "            ],\n",
        "            Dict[str, Scalar],\n",
        "            FitResultsAndFailures,\n",
        "        ]\n",
        "    ]:\n",
        "        \"\"\"Perform a single round of federated averaging.\"\"\"\n",
        "\n",
        "        # Get clients and their respective instructions from strategy\n",
        "        client_instructions = self.strategy.configure_fit(\n",
        "            server_round=server_round,\n",
        "            parameters=self.parameters,\n",
        "            client_manager=self._client_manager,\n",
        "        )\n",
        "\n",
        "        if not client_instructions:\n",
        "            log(INFO, \"fit_round %s: no clients selected, cancel\", server_round)\n",
        "            return None\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"fit_round %s: strategy sampled %s clients (out of %s)\",\n",
        "            server_round,\n",
        "            len(client_instructions),\n",
        "            self._client_manager.num_available(),\n",
        "        )\n",
        "\n",
        "        # Collect `fit` results from all clients participating in this round\n",
        "        results, failures = fit_clients(\n",
        "            client_instructions=client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "        )\n",
        "\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"fit_round %s received %s results and %s failures\",\n",
        "            server_round,\n",
        "            len(results),\n",
        "            len(failures),\n",
        "        )\n",
        "\n",
        "        # Aggregate training results\n",
        "        NN_aggregated: Parameters\n",
        "        trees_aggregated: Union[\n",
        "            Tuple[XGBClassifier, int],\n",
        "            Tuple[XGBRegressor, int],\n",
        "            List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "        ]\n",
        "        metrics_aggregated: Dict[str, Scalar]\n",
        "        aggregated, metrics_aggregated = self.strategy.aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "        NN_aggregated, trees_aggregated = aggregated[0], aggregated[1]\n",
        "\n",
        "        if type(trees_aggregated) is list:\n",
        "            print(\"Server side aggregated\", len(trees_aggregated), \"trees.\")\n",
        "        else:\n",
        "            print(\"Server side did not aggregate trees.\")\n",
        "\n",
        "        return (\n",
        "            [NN_aggregated, trees_aggregated],\n",
        "            metrics_aggregated,\n",
        "            (results, failures),\n",
        "        )\n",
        "\n",
        "    def _get_initial_parameters(\n",
        "        self, timeout: Optional[float]\n",
        "    ) -> Tuple[Parameters, Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]]:\n",
        "        \"\"\"Get initial parameters from one of the available clients.\"\"\"\n",
        "\n",
        "        # Server-side parameter initialization\n",
        "        parameters: Optional[Parameters] = self.strategy.initialize_parameters(\n",
        "            client_manager=self._client_manager\n",
        "        )\n",
        "        if parameters is not None:\n",
        "            log(INFO, \"Using initial parameters provided by strategy\")\n",
        "            return parameters\n",
        "\n",
        "        # Get initial parameters from one of the clients\n",
        "        log(INFO, \"Requesting initial parameters from one random client\")\n",
        "        random_client = self._client_manager.sample(1)[0]\n",
        "        ins = GetParametersIns(config={})\n",
        "        group_id = random_client.cid  # Use client ID as group ID\n",
        "        get_parameters_res_tree = random_client.get_parameters(ins=ins, group_id=group_id, timeout=timeout)\n",
        "        parameters = [get_parameters_res_tree[0].parameters, get_parameters_res_tree[1], ]\n",
        "        log(INFO, \"Received initial parameters from one random client\")\n",
        "\n",
        "        return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "dUYOpupMurKw"
      },
      "outputs": [],
      "source": [
        "def print_model_layers(model: nn.Module) -> None:\n",
        "    print(model)\n",
        "    for param_tensor in model.state_dict():\n",
        "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "\n",
        "def serverside_eval(\n",
        "    server_round: int,\n",
        "    parameters: Tuple[\n",
        "        Parameters,\n",
        "        Union[\n",
        "            Tuple[XGBClassifier, int],\n",
        "            Tuple[XGBRegressor, int],\n",
        "            List[Union[Tuple[XGBClassifier, int], Tuple[XGBRegressor, int]]],\n",
        "        ],\n",
        "    ],\n",
        "    config: Dict[str, Scalar],\n",
        "    task_type: str,\n",
        "    testloader: DataLoader,\n",
        "    batch_size: int,\n",
        "    client_tree_num: int,\n",
        "    client_num: int,\n",
        ") -> Tuple[float, Dict[str, float]]:\n",
        "    \"\"\"An evaluation function for centralized/serverside evaluation over the entire test set.\"\"\"\n",
        "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = \"cpu\"\n",
        "    model = CNN()\n",
        "    # print_model_layers(model)\n",
        "\n",
        "    model.set_weights(parameters_to_ndarrays(parameters[0]))\n",
        "    model.to(device)\n",
        "    trees_aggregated = parameters[1]\n",
        "    # Chekc this testloader\n",
        "    testloader = tree_encoding_loader(\n",
        "        testloader, batch_size, trees_aggregated, client_tree_num, client_num\n",
        "    )\n",
        "    loss, result, _ = test(\n",
        "        task_type, model, testloader, device=device, log_progress=False\n",
        "    )\n",
        "\n",
        "    if task_type == \"MULTICLASS\":\n",
        "        print(\n",
        "            f\"Evaluation on the server: test_loss={loss:.4f}, test_accuracy={result:.4f}\"\n",
        "        )\n",
        "        return loss, {\"accuracy\": result}\n",
        "    elif task_type == \"REG\":\n",
        "        print(f\"Evaluation on the server: test_loss={loss:.4f}, test_mse={result:.4f}\")\n",
        "        return loss, {\"mse\": result}\n",
        "\n",
        "\n",
        "def start_experiment(\n",
        "    task_type: str,\n",
        "    trainset: Dataset,\n",
        "    testset: Dataset,\n",
        "    num_rounds: int = 5,\n",
        "    client_tree_num: int = 50,\n",
        "    client_pool_size: int = 5,\n",
        "    num_iterations: int = 100,\n",
        "    fraction_fit: float = 1.0,\n",
        "    min_fit_clients: int = 2,\n",
        "    batch_size: int = 32,\n",
        "    val_ratio: float = 0.1,\n",
        ") -> History:\n",
        "    client_resources = {\"num_cpus\": 10}  # 2 clients per CPU\n",
        "\n",
        "    # Partition the dataset into subsets reserved for each client.\n",
        "    # - 'val_ratio' controls the proportion of the (local) client reserved as a local test set\n",
        "    # (good for testing how the final model performs on the client's local unseen data)\n",
        "\n",
        "    trainloaders, valloaders, testloader = do_fl_partitioning(\n",
        "        trainset,\n",
        "        testset,\n",
        "        batch_size=\"whole\",\n",
        "        pool_size=client_pool_size,\n",
        "        val_ratio=val_ratio,\n",
        "    )\n",
        "    print(\n",
        "        f\"Data partitioned across {client_pool_size} clients\"\n",
        "        f\" and {val_ratio} of local dataset reserved for validation.\"\n",
        "    )\n",
        "\n",
        "    # Configure the strategy\n",
        "    def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "        print(f\"Configuring round {server_round}\")\n",
        "        return {\n",
        "            \"num_iterations\": num_iterations,\n",
        "            \"batch_size\": batch_size,\n",
        "        }\n",
        "\n",
        "    # FedXgbNnAvg\n",
        "    strategy = FedXgbNnAvg(\n",
        "        fraction_fit=fraction_fit,\n",
        "        fraction_evaluate=fraction_fit if val_ratio > 0.0 else 0.0,\n",
        "        min_fit_clients=min_fit_clients,\n",
        "        min_evaluate_clients=min_fit_clients,\n",
        "        min_available_clients=client_pool_size,  # all clients should be available\n",
        "        on_fit_config_fn=fit_config,\n",
        "        on_evaluate_config_fn=(lambda r: {\"batch_size\": batch_size}),\n",
        "        evaluate_fn=functools.partial(\n",
        "            serverside_eval,\n",
        "            task_type=task_type,\n",
        "            testloader=testloader,\n",
        "            batch_size=batch_size,\n",
        "            client_tree_num=client_tree_num,\n",
        "            client_num=client_num,\n",
        "        ),\n",
        "        accept_failures=False,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"FL experiment configured for {num_rounds} rounds with {client_pool_size} client in the pool.\"\n",
        "    )\n",
        "    print(\n",
        "        f\"FL round will proceed with {fraction_fit * 100}% of clients sampled, at least {min_fit_clients}.\"\n",
        "    )\n",
        "\n",
        "    def client_fn(cid) -> fl.client.Client:\n",
        "        \"\"\"Creates a federated learning client\"\"\"\n",
        "        if val_ratio is not None and 0.0 < val_ratio <= 1.0:\n",
        "            print(\"Fl with validation\")\n",
        "            # print(val_ratio)\n",
        "            return FL_Client(\n",
        "                task_type,\n",
        "                trainloaders[int(cid)],\n",
        "                valloaders[int(cid)],\n",
        "                client_tree_num,\n",
        "                client_pool_size,\n",
        "                num_classes=12,\n",
        "                cid=cid,\n",
        "                log_progress=False,\n",
        "            )\n",
        "        else:\n",
        "            print(\"Fl with validation\")\n",
        "            return FL_Client(\n",
        "                task_type,\n",
        "                trainloaders[int(cid)],\n",
        "                None,\n",
        "                client_tree_num,\n",
        "                client_pool_size,\n",
        "                num_classes=12,\n",
        "                cid=cid,\n",
        "                log_progress=False,\n",
        "            )\n",
        "\n",
        "    # Start the simulation\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        server=FL_Server(client_manager=SimpleClientManager(), strategy=strategy),\n",
        "        num_clients=client_pool_size,\n",
        "        client_resources=client_resources,\n",
        "        config=ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print(history)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5qvKlmhhurIP",
        "outputId": "3ec36a45-5ce0-42dc-a764-1a15f9510e39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `FedXgbNnAvg` strategy\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[93mWARNING \u001b[0m:   Both server and strategy were provided, ignoring strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainloaders data shape: torch.Size([23731, 17]), Label shape: torch.Size([23731])\n",
            "Testloaders data shape: torch.Size([13960, 17]), Label shape: torch.Size([13960])\n",
            "Data partitioned across 3 clients and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 3 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-23 19:14:16,359\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 33953879655.0, 'CPU': 12.0, 'accelerator_type:L4': 1.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 16976939827.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 10}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "\u001b[92mINFO \u001b[0m:      Initializing global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[91mERROR \u001b[0m:     RayActorClientProxy.get_parameters() missing 1 required positional argument: 'group_id'\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\", line 323, in start_simulation\n",
            "    hist = run_fl(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\", line 490, in run_fl\n",
            "    hist, elapsed_time = server.fit(\n",
            "  File \"<ipython-input-134-f477193a3703>\", line 20, in fit\n",
            "    self.parameters = self._get_initial_parameters(timeout=timeout)\n",
            "  File \"<ipython-input-134-f477193a3703>\", line 229, in _get_initial_parameters\n",
            "    get_parameters_res_tree = random_client.get_parameters(ins=ins, timeout=timeout)\n",
            "TypeError: RayActorClientProxy.get_parameters() missing 1 required positional argument: 'group_id'\n",
            "\n",
            "\u001b[91mERROR \u001b[0m:     Your simulation crashed :(. This could be because of several reasons. The most common are: \n",
            "\t > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: \n",
            "\t\t - You might be using a class attribute in your clients that hasn't been defined.\n",
            "\t\t - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).\n",
            "\t\t - The return types of methods in your clients/strategies might be incorrect.\n",
            "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
            "\t > All the actors in your pool crashed. This could be because: \n",
            "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 10} is not enough for your run). Use fewer concurrent actors. \n",
            "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 10}.\n",
            "Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Simulation crashed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         hist = run_fl(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     hist, elapsed_time = server.fit(\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-f477193a3703>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Initializing global parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_initial_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-f477193a3703>\u001b[0m in \u001b[0;36m_get_initial_parameters\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mgroup_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcid\u001b[0m  \u001b[0;31m# Use client ID as group ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mget_parameters_res_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_parameters_res_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_parameters_res_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_parameters_res_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: RayActorClientProxy.get_parameters() missing 1 required positional argument: 'group_id'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-13d929190bfd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m start_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MULTICLASS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrainset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtestset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-ec744dcc3787>\u001b[0m in \u001b[0;36mstart_experiment\u001b[0;34m(task_type, trainset, testset, num_rounds, client_tree_num, client_pool_size, num_iterations, fraction_fit, min_fit_clients, batch_size, val_ratio)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Start the simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     history = fl.simulation.start_simulation(\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mclient_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFL_Server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSimpleClientManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mclient_resources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         )\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Simulation crashed.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Simulation crashed."
          ]
        }
      ],
      "source": [
        "start_experiment(\n",
        "    task_type='MULTICLASS',\n",
        "    trainset=trainset,\n",
        "    testset=testset,\n",
        "    num_rounds=10,\n",
        "    client_tree_num=client_tree_num,\n",
        "    client_pool_size=client_num,\n",
        "    num_iterations=150,\n",
        "    batch_size=64,\n",
        "    fraction_fit=1.0,\n",
        "    min_fit_clients=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V3RcY2DurFX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
